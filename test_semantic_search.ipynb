{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Implementing semantic search within a document using word embeddings__  \n",
    "https://towardsdatascience.com/beyond-ctrl-f-44f4bec892e9  \n",
    "https://github.com/fabio-a-oliveira/semantic-search/blob/main/semantic_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll apply _Natural Language Processing (NLP)_ techniques to implement a semantic search within a document.  \n",
    "This means that, instead of searching for a literal word or sequence of words (as you would when you use `CTRL+F` in Notepad, Microsoft Word etc), we'll be searching for terms, sentences or paragraphs of ___similar meaning___. If you ever had to search a massive document for a piece of information that you cannot recall exactly, you will agree that this application can be extremely useful and time-saving.\n",
    "\n",
    "In summary, this is what we are going to do:\n",
    "\n",
    "1. Use ___word embeddings___ to convert every word in the book and the requested sentence to a dense vector representation (in this case, we'll use GloVe embeddings);\n",
    "2. Apply a ___part-of-speech___ (POS) mask to both the book and the requested sentence: every word that does not belong to a list of relevant _parts-of-speech_ will have the embedding converted to a null vector;\n",
    "3. Apply a ___bag-of-words___ approach to sentence embedding: average the embeddings of every word in the sentence and get a single vector to represent its semantic content;\n",
    "4. Apply the _bag-of-words_ sentence embedding and POS filter to the entire book by using a ___sliding window___ with the length of the requested sentence plus a selected margin and averaging the embeddings of words within the window;\n",
    "5. Calculate the ___cosine distance___ between the requested sentence embedding and the sliding window embeddings\n",
    "6. Select the position in the book with the shortest distance to the requested sentence.\n",
    "\n",
    "To illustrate the concept, we'll download the .txt file of the book _Pride and Prejudice_ from the Project Gutenberg website and we'll show two applications of the technique:\n",
    "\n",
    "1. We will take a sentence from the book and search the text for several increasingly altered versions of it;\n",
    "2. We will take several excerpts from the Brazilian Portuguese version of the book, translate them back to English (which results in sentences with equivalent meaning but significantly different wording), and find the correspoding match in the original version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of the NLP resources we need are available in the `nltk` (Natural Language Toolkit) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/catsmile/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/catsmile/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests, nltk\n",
    "\n",
    "from os import mkdir, getcwd, listdir\n",
    "from os.path import join\n",
    "from zipfile import ZipFile\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "HOME = getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and prepare word embeddings and Project Gutenberg catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heart and soul of capturing word meaning will be provided by GloVe word embeddings.   \n",
    "In order to use them, we download the embeddings from the Stanford NLP website and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data' not in listdir(): mkdir('data')\n",
    "\n",
    "if 'glove.6B.zip' not in listdir(join(HOME, 'data')):\n",
    "    URL_GloVe = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    r = requests.get(URL_GloVe).content\n",
    "    with open(join('data', 'glove.6B.zip'), 'wb') as file:\n",
    "        file.write(r)\n",
    "\n",
    "if 'glove.6B.300d.txt' not in listdir(join(HOME, 'GldataoVe')):\n",
    "    z = ZipFile(join(HOME, 'data','glove.6B.zip'))\n",
    "    z.extractall(join(HOME, 'data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the raw data to a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "\n",
    "with open(join(HOME, 'data', 'glove.6B.300d.txt')) as file:\n",
    "    for line in file:\n",
    "        word, vector = line.split(' ', maxsplit=1)\n",
    "        vector = np.array(vector.split(' ')).astype('float')\n",
    "        embedding_dict.update({word:vector})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_embedding(content, embedding_dict, \n",
    "                       allowed_pos = ['NN','NNS','NNP','NNPS','JJ','RB','VB',\n",
    "                                      'VBG','VBN','VBP','VBZ','VBD']):\n",
    "    \"\"\"Takes text content as a string and returns a matrix with the embeddings for each word according to a given dictionary.\n",
    "        Use a list of allowed parts-of-speech, to give more control over what categories of words will be kept or masked out.\n",
    "        This list, also known as list of ___stop words___ - frequently occurrying words that can be removed from the bag-of-words representation without much loss of meaning.\n",
    "\n",
    "    Args:\n",
    "        content (str): String to be embedded\n",
    "        embedding_dict (dictionary): Embedding dictionary\n",
    "        allowed_pos (list, optional): List of allowed parts-of-speech. Defaults to ['NN','NNS','NNP','NNPS','JJ','RB','VB', 'VBG','VBN','VBP','VBZ','VBD'].\n",
    "\n",
    "    Returns:\n",
    "        np.array: The embedded `content`.\n",
    "    \"\"\"\n",
    "\n",
    "    # basic cleanup\n",
    "    content = content.replace('\\n', ' ').replace('_', \"\").lower()\n",
    "\n",
    "    # tokenize content\n",
    "    tokens = nltk.word_tokenize(content)\n",
    "\n",
    "    # get mask indicating tokens that are in or out of allowed parts-of-speech\n",
    "    pos_mask = np.array([int(tag[1] in allowed_pos) \n",
    "                         for tag in nltk.pos_tag(tokens)]).reshape((-1,1))\n",
    "\n",
    "    # get embedding and apply mask\n",
    "    embedding_dim = len(list(embedding_dict.values())[0])\n",
    "    embedding = np.array([embedding_dict[token] \n",
    "                          if token in embedding_dict.keys() \n",
    "                          else np.zeros(embedding_dim) \n",
    "                          for token in tokens])\n",
    "    embedding *= pos_mask\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def cosine_distance(vec1, vec2):\n",
    "    \"\"\"Calculate the _cosine distance_ between embeddings.\n",
    "        Standalone function from the one in `scipy` package\n",
    "\n",
    "    Args:\n",
    "        vec1 (np.array): Embedding 1\n",
    "        vec2 (np.array): Embedding 2\n",
    "\n",
    "    Returns:\n",
    "        int: Distance between Embedding 1 and 2\n",
    "    \"\"\"\n",
    "\n",
    "    dot_prod = np.dot(vec1, vec2)\n",
    "    norm1 = np.sqrt(np.sum(vec1 ** 2))\n",
    "    norm2 = np.sqrt(np.sum(vec2 ** 2))\n",
    "\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 - dot_prod / (norm1 * norm2)\n",
    "    \n",
    "def sliding_distance(book, excerpt, margin = 0):\n",
    "    \"\"\"Calculates the cosine distance between \n",
    "        - the input exerpt (embedded exerpt)\n",
    "        - each possible sentence in the book (the embeddings of a sliding window of words throughout the entire book)\n",
    "\n",
    "    Args:\n",
    "        book (np.array): The embedded book\n",
    "        excerpt (np.array): The embedded input excerpt\n",
    "        margin (int, optional): To search for sentences that are longer than the provided excerpt. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The array\n",
    "    \"\"\"\n",
    "\n",
    "    # The length of the sliding window corresponds to the length of the given excerpt plus a selected margin.  \n",
    "    mvg_avg_widgth = excerpt.shape[0] + margin\n",
    "\n",
    "    # bag-of-words excerpt embedding\n",
    "    excerpt_embedding = excerpt.mean(axis=0)\n",
    "\n",
    "    # moving average of the book embedding, \n",
    "    # considering the length of the excerpt + a margin\n",
    "    mvg_avg_embedding = np.array([book[line-mvg_avg_widgth:line].mean(axis=0) \n",
    "                            for line in range(mvg_avg_widgth, book.shape[0])])\n",
    "\n",
    "    # sliding distance: distance between sliding window and excerpt embeddings\n",
    "    distance = np.array([cosine_distance(mvg_avg_embedding[line,:], \n",
    "                                         excerpt_embedding) \n",
    "                         for line in range(mvg_avg_embedding.shape[0])])\n",
    "\n",
    "    return distance\n",
    "\n",
    "def find_match(reference, match_position, match_length):\n",
    "    \"\"\"Takes a chosen `match_position` and sentence `match_length` and returns the corresponding excerpt from the `reference`.  \n",
    "\n",
    "    Args:\n",
    "        reference (str): The document in raw text.\n",
    "        match_position (int): tokenized position to be extracted\n",
    "        match_length (int): number of tokens to extract starting from `match_position`\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # basic cleanup\n",
    "    reference = reference.replace('\\n', ' ').replace('_', \"\").lower()\n",
    "\n",
    "    match = nltk.word_tokenize(reference)\n",
    "    match = match[match_position : match_position + match_length]\n",
    "    match = ' '.join(match).replace(' ,',',').replace(' .','.')\n",
    "    return \"[\"+str(match_position)+\"] \"+match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_excerpt(excerpt, book, margin = 0, count = 1):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        excerpt (str): The input exerpt to be searched.\n",
    "        book (str): The document in raw text.\n",
    "        margin (int, optional): To search for sentences that are longer than the provided excerpt. Defaults to 0.\n",
    "        count (int, optional): Number of excerpts to search for. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: Excerpts found from the book\n",
    "    \"\"\"\n",
    "\n",
    "    # embed excerpt and get word count\n",
    "    book_embedding = sequence_embedding(book, embedding_dict)\n",
    "    excerpt_embedding = sequence_embedding(excerpt, embedding_dict)\n",
    "    excerpt_word_count = len(nltk.word_tokenize(excerpt))\n",
    "\n",
    "    # calculate distances\n",
    "    distances = sliding_distance(book_embedding, excerpt_embedding, margin = margin)\n",
    "\n",
    "    # find match and print it\n",
    "    # find_match(book, distances.argmin(), excerpt_word_count + margin)\n",
    "    \n",
    "    # `ndarray.argmin()` method to find the position with the smallest distance.\n",
    "    # `ndarray.argsort()` method to get the top distances starting from the smallest\n",
    "    return [ find_match(book, distances.argsort()[i], excerpt_word_count + 2*margin) \n",
    "                for i in range(count) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "def merge_overlapping_results(data_sentences, similarity_threshold=0.4):\n",
    "    \"\"\"From a list of sentences, group them into clusters based on their similarity\n",
    "\n",
    "    Args:\n",
    "        data_sentences (list): List of sentences\n",
    "        similarity_threshold (float, optional): Threshold to group sentences. Lower the stricter. Defaults to 0.4.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary: A dictionary of clusters and their sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the spaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Calculate sentence embeddings using spaCy\n",
    "    data_embeddings = [nlp(sentence).vector for sentence in data_sentences]\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(data_embeddings)\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(similarity_matrix, method='complete')\n",
    "\n",
    "    # Apply clustering with a similarity threshold\n",
    "    cluster_labels = fcluster(linkage_matrix, t=similarity_threshold, criterion='distance')\n",
    "\n",
    "    # Initialize a dictionary to store merged results for each cluster\n",
    "    merged_results = {}\n",
    "\n",
    "    # Group sentences by cluster label\n",
    "    for idx, cluster_label in enumerate(cluster_labels):\n",
    "        if cluster_label not in merged_results:\n",
    "            merged_results[cluster_label] = [data_sentences[idx]]\n",
    "        else:\n",
    "            merged_results[cluster_label].append(data_sentences[idx])\n",
    "\n",
    "    return list(merged_results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First application__  \n",
    "Take a sentence from the book and search the document for several modified versions of it.\n",
    "\n",
    "__Second application__  \n",
    "Take several sentences from the Brazilian Portuguese translation of the book, translate them back to English and search the book for them.  \n",
    "(which results in excerpts with similar meaning but very different wordings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Search for excerpts from a given input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare book and convert every word to its dense vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'book.txt' not in listdir(join(HOME, 'data')):\n",
    "    URL = \"https://www.gutenberg.org/cache/epub/42671/pg42671.txt\"\n",
    "    r = str(requests.get(URL).content, encoding='utf-8')\n",
    "    with open(join('data', 'book.txt'), 'w') as file:\n",
    "        file.write(r)\n",
    "\n",
    "with open(join('data', 'book.txt'), 'r') as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Searching for the original sentence, just to get a feel for the technique and make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[324] it is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt = (\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\")\n",
    "locate_excerpt(excerpt, book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Make it a little more difficult and change some of the words for synonims.\n",
    "\n",
    "Outcome  \n",
    "\n",
    "```\n",
    "We can see that there is a slight misalignment in the result: the first 4 words are missing, and 3 additional words (or 4 tokens, considering the dot) are added to the end.  \n",
    "This is a frequent artifact of the response.  \n",
    "Since we are working with sliding windows, there is a large overlap between sentences,  \n",
    "and results will be often ofset by a few words to the right or left.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[328] universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. however little known']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt = (\"It is a fact universally known, that an unmarried man in possession of a vast fortune, must be in need of a wife\")\n",
    "locate_excerpt(excerpt, book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Going beyond synonims and alter the sentence more substantially, including some simplifications\n",
    "- Because we are providing an excerpt that is somewhat shorter than the original, adding a margin to increase the length of the sliding window will help in locating the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[324] it is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a man may be']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt = (\"It is a fact universally known, that a man who is rich and single surely wants a wife\")\n",
    "locate_excerpt(excerpt, book, margin = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Try an extreme example and provide just the gist of the sentence as an excerpt for the algorithm\n",
    "\n",
    "Outcome  \n",
    "\n",
    "```\n",
    "That did not go very well. \n",
    "The algorithm found a match that does not correspond to the original sentence we wanted in the book.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[83860] as he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt = \"Everyone knows that a rich single man wants a wife\"\n",
    "locate_excerpt(excerpt, book, margin = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Cycle through the top results and see if the actual sentence pops up:\n",
    "\n",
    "Outcome  \n",
    "\n",
    "```\n",
    "Looking carefully at the top 20 results, we see that the original excerpt we were looking for corresponds to entries 5, 6, 15, and 17. There is a lot of overlap between results, so there are actually just 7 different parts in this selection, of which our desired outcome is the third.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83860] as he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i\n",
      "[111794] is such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i\n",
      "[111793] he is such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that\n",
      "[83861] he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i would\n",
      "[330] , that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a\n",
      "[329] acknowledged, that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such\n",
      "[111796] a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want very\n",
      "[111797] man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want very much\n",
      "[83862] chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i would not\n",
      "[133624] said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she only came\n",
      "[133623] '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she only\n",
      "[133622] , '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she\n",
      "[133621] it, '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for\n",
      "[123466] perpetually talked of. my mother means well ; but she does not know, no one can know how much i suffer from what she says. happy shall\n",
      "[331] that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a man\n",
      "[111795] such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want\n",
      "[332] a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a man may\n",
      "[116948] room, `` and what do you think of my husband ? is not he a charming man ? i am sure my sisters must all envy me. i\n",
      "[83854] , well ! it is just as he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and\n",
      "[41301] every thing else she is as good natured a girl as ever lived. i will go directly to mr. bennet, and we shall very soon settle it with\n"
     ]
    }
   ],
   "source": [
    "# define excerpt\n",
    "excerpt = \"Everyone knows that a rich single man wants a wife\"\n",
    "margin = 10\n",
    "\n",
    "# find top 20 results and print them\n",
    "excerpts = locate_excerpt(excerpt, book, margin = 10, count = 20)\n",
    "print(\"\\n\".join(excerpts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Identify the overlaps and merges them into single results.  \n",
    "In that case, our desired excerpt would be the third result on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      "[83860] as he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i\n",
      "[83861] he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i would\n",
      "[83862] chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and if i was her, i would not\n",
      "[83854] , well ! it is just as he chooses. nobody wants him to come. though i shall always say that he used my daughter extremely ill ; and\n",
      "==================================================\n",
      "Cluster 2:\n",
      "[111794] is such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i\n",
      "[111793] he is such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that\n",
      "[111796] a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want very\n",
      "[111797] man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want very much\n",
      "[111795] such a man ! '' `` yes, yes, they must marry. there is nothing else to be done. but there are two things that i want\n",
      "==================================================\n",
      "Cluster 3:\n",
      "[330] , that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a\n",
      "[329] acknowledged, that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such\n",
      "[331] that a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a man\n",
      "[332] a single man in possession of a good fortune, must be in want of a wife. however little known the feelings or views of such a man may\n",
      "==================================================\n",
      "Cluster 4:\n",
      "[133624] said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she only came\n",
      "[133623] '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she only\n",
      "[133622] , '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for she\n",
      "[133621] it, '' said her daughter, `` she would go. '' `` she is a very fine-looking woman ! and her calling here was prodigiously civil ! for\n",
      "==================================================\n",
      "Cluster 5:\n",
      "[123466] perpetually talked of. my mother means well ; but she does not know, no one can know how much i suffer from what she says. happy shall\n",
      "==================================================\n",
      "Cluster 6:\n",
      "[116948] room, `` and what do you think of my husband ? is not he a charming man ? i am sure my sisters must all envy me. i\n",
      "==================================================\n",
      "Cluster 7:\n",
      "[41301] every thing else she is as good natured a girl as ever lived. i will go directly to mr. bennet, and we shall very soon settle it with\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Merge overlapping results\n",
    "merged_results = merge_overlapping_results(excerpts)\n",
    "\n",
    "# Print merged results\n",
    "for idx, cluster in enumerate(merged_results, start=1):\n",
    "    print(f\"Cluster {idx}:\")\n",
    "    print(\"\\n\".join(cluster))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In an actual application, \n",
    "it might be necessary for the user to try a couple of different values for the `margin` parameter  \n",
    "or to scroll through a short list of candidate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Search for original text from translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of searching for sentences with the same meaning,  \n",
    "we will look for excerpts corresponding to the Brazilian Portuguese translation.\n",
    "\n",
    "For each of these excerpts, \n",
    "1. use the `googletrans` library to translate them into English.  \n",
    "2. use `locate_excerpt` to try and find the corresponding excerpt in the English book. \n",
    "\n",
    "Things to take note\n",
    "- You will notice that the translation is rather different from the original text. \n",
    "- Although it certainly holds the same meaning, the choice and order of words is remarkably different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Test single sentences of translated excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excerpt (pt):\n",
      "É uma verdade universalmente conhecida que um homem solteiro,\n",
      "possuidor de uma boa fortuna, deve estar necessitado de esposa.\n",
      "\n",
      "Translation (en):\n",
      "It is a universally known truth that a single man, possessed of a good\n",
      "fortune, must be in need of a wife.\n",
      "\n",
      "Original (en):\n",
      "[324] it is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife\n",
      "==================================================\n",
      "Excerpt (pt):\n",
      "Mas quando Elizabeth contou que ele ficara em silêncio, a hipótese não\n",
      "pareceu muito plausível, mesmo para Charlotte que a desejava.\n",
      "\n",
      "Translation (en):\n",
      "But when Elizabeth told him that he had been silent, the hypothesis\n",
      "did not seem very plausible, even to Charlotte who wanted her.\n",
      "\n",
      "Original (en):\n",
      "[66371] elizabeth told of his silence, it did not seem very likely, even to charlotte 's wishes, to be the case ; and after\n",
      "==================================================\n",
      "Excerpt (pt):\n",
      "Mrs. Gardiner ficou surpreendida e preocupada. Mas como se aproximavam\n",
      "agora do lugar onde residira na sua mocidade, ela se entregou toda ao\n",
      "encanto das suas recordações\n",
      "\n",
      "Translation (en):\n",
      "Mrs. Gardiner was surprised and worried. But as they now approached\n",
      "the place where she had resided in her youth, she gave herself up\n",
      "entirely to the charm of her memories.\n",
      "\n",
      "Original (en):\n",
      "[94632] . mrs. gardiner was surprised and concerned ; but as they were now approaching the scene of her former pleasures, every idea gave way to the charm of recollection ; and she was\n",
      "==================================================\n",
      "Excerpt (pt):\n",
      "— Acha que eles estão em Londres? — Sim, em que outro lugar poderiam\n",
      "se esconder?\n",
      "\n",
      "Translation (en):\n",
      "'Do you think they're in London?' \"Yes, where else could they hide?\"\n",
      "\n",
      "Original (en):\n",
      "[110225] . '' `` do you suppose them to be in london ? '' `` yes ; where else can\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import googletrans\n",
    "from textwrap import wrap\n",
    "\n",
    "list_excerpts_translated = [\"É uma verdade universalmente conhecida que um homem solteiro, possuidor de uma boa fortuna, deve estar necessitado de esposa.\"\n",
    "                      , \"Mas quando Elizabeth contou que ele ficara em silêncio, a hipótese não pareceu muito plausível, mesmo para Charlotte que a desejava.\"\n",
    "                      , \"Mrs. Gardiner ficou surpreendida e preocupada. Mas como se aproximavam agora do lugar onde residira na sua mocidade, ela se entregou toda ao encanto das suas recordações\"\n",
    "                      , \"— Acha que eles estão em Londres? — Sim, em que outro lugar poderiam se esconder?\"]\n",
    "\n",
    "for e in list_excerpts_translated:\n",
    "    excerpt_english = googletrans.Translator().translate(e).text\n",
    "    result = locate_excerpt(excerpt_english, book)\n",
    "\n",
    "    print(\"Excerpt (pt):\")\n",
    "    [print(st) for st in wrap(e)]\n",
    "    print(\"\\nTranslation (en):\")\n",
    "    [print(st) for st in wrap(excerpt_english)]\n",
    "    print(\"\\nOriginal (en):\")\n",
    "    [print(st) for st in result]\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Try a longer excerpt with several sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excerpt (pt):\n",
      "Se pudéssemos saber quais eram as dívidas de Wickham... E com quanto\n",
      "ele dotou nossa irmã... Saberia exatamente o que Mr. Gardiner fez,\n",
      "pois Wickham não tem um tostão de seu. A bondade dos nossos tios é uma\n",
      "coisa que nunca poderá ser paga. Eles a levaram para casa e lhe deram\n",
      "toda a sua proteção e apoio moral. Isto é um sacrifício que anos de\n",
      "gratidão não podem compensar. Nesse momento, ela está em casa deles.\n",
      "Se uma tão grande bondade não lhe der a consciência da falta que\n",
      "praticou, é que ela não merece nunca ser feliz. Imagina a sua cara\n",
      "quando chegar diante da minha tia\n",
      "\n",
      "Translation (en):\n",
      "If we could only know what Wickham's debts were... And how much he\n",
      "endowed our sister with... We would know exactly what Mr. Gardiner\n",
      "did, for Wickham has not a penny of his. The kindness of our uncles is\n",
      "something that can never be repaid. They took her home and gave her\n",
      "all their protection and moral support. This is a sacrifice that years\n",
      "of gratitude cannot make up for. Right now, she's at their house. If\n",
      "such great kindness does not make him aware of the fault he has\n",
      "committed, it is because he never deserves to be happy. Imagine her\n",
      "face when she arrives in front of my aunt\n",
      "\n",
      "Original (en):\n",
      "[112247] debts have been, '' said elizabeth, `` and how much is settled on his side on our sister, we shall exactly know what mr. gardiner has done for them, because wickham has not sixpence of his own. the kindness of my uncle and aunt can never be requited. their taking her home, and affording her their personal protection and countenance, is such a sacrifice to her advantage, as years of gratitude can not enough acknowledge. by this time she is actually with them ! if such goodness does not make her miserable now, she will never deserve to be happy ! what a meeting for her, when she first sees my aunt !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt_translated = (\"Se pudéssemos saber quais eram as dívidas de Wickham... E com quanto ele dotou nossa irmã... Saberia exatamente o que Mr. Gardiner fez, pois Wickham não tem um tostão de seu. A bondade dos nossos tios é uma coisa que nunca poderá ser paga. Eles a levaram para casa e lhe deram toda a sua proteção e apoio moral. Isto é um sacrifício que anos de gratidão não podem compensar. Nesse momento, ela está em casa deles. Se uma tão grande bondade não lhe der a consciência da falta que praticou, é que ela não merece nunca ser feliz. Imagina a sua cara quando chegar diante da minha tia\")\n",
    "\n",
    "excerpt_english = googletrans.Translator().translate(excerpt_translated).text\n",
    "result = locate_excerpt(excerpt_english, book)\n",
    "\n",
    "print(\"Excerpt (pt):\")\n",
    "[print(st) for st in wrap(excerpt_translated)]\n",
    "print(\"\\nTranslation (en):\")\n",
    "[print(st) for st in wrap(excerpt_english)]\n",
    "print(\"\\nOriginal (en):\")\n",
    "[print(st) for st in result]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
